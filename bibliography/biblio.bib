@Manual{rplos,
  title = {{rplos: Interface to the Search API for the 'PLoS' Journals}},
  author = {Scott Chamberlain and Carl Boettiger and Karthik Ram},
  year = {2015},
  note = {R package version 0.4.7},
  url = {{http://CRAN.R-project.org/package=rplos}},
}


@Manual{rcran,
  title = {{R: A Language and Environment for Statistical Computing}},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2015},
  url = {{http://www.R-project.org/}},
}


@MISC{Himmelstein2015-me,
  title = {{Publication delays at {PLOS} and 3,475 other journals}},
  booktitle = {Satoshi Village},
  author = {Himmelstein, Daniel},
  month = {29~ # jun},
  year = {2015},
  url = {http://web.archive.org/web/20150701055009/http://blog.dhimmel.com/plos-and-publishing-delays/},
  howpublished = {\url{http://web.archive.org/web/20150701055009/http://blog.dhimmel.com/plos-and-publishing-delays/}},
  note = {Accessed: 2015-7-1},
}


@article{ioannidis1998,
  author = {Ioannidis JA},
  title = {{EFfect of the statistical significance of results on the time to completion and publication of randomized efficacy trials}},
  journal = {JAMA},
  volume = {279},
  number = {4},
  pages = {281-286},
  year = {1998},
  doi = {10.1001/jama.279.4.281},
  url = {+ http://dx.doi.org/10.1001/jama.279.4.281},
  eprint = {/data/Journals/JAMA/4545/JOC71198.pdf},
  abstract = {Context.— Medical evidence may be biased over time if completion and publication of randomized efficacy trials are delayed when results are not statistically significant. Objective.— To evaluate whether the time to completion and the time to publication of randomized phase 2 and phase 3 trials are affected by the statistical significance of results and to describe the natural history of such trials. Design.— Prospective cohort of randomized efficacy trials conducted by 2 trialist groups from 1986 to 1996. Setting.— Multicenter trial groups in human immunodeficiency virus infection sponsored by the National Institutes of Health. Patients.— A total of 109 efficacy trials (total enrollment, 43708 patients). Main Outcome Measures.— Time from start of enrollment to completion of follow-up and time from completion of follow-up to peer-reviewed publication assessed with survival analysis. Results.— The median time from start of enrollment to publication was 5.5 years and was substantially longer for negative trials than for results favoring an experimental arm (6.5 vs 4.3 years, respectively; P<.001; hazard ratio for time to publication for positive vs negative trials, 3.7; 95% confidence interval [CI], 1.8-7.7). This difference was mostly attributable to differences in the time from completion to publication (median, 3.0 vs 1.7 years for negative vs positive trials; P<.001). On average, trials with significant results favoring any arm completed follow-up slightly earlier than trials with nonsignificant results (median, 2.3 vs 2.5 years; P=.045), but long-protracted trials often had low event rates and failed to reach statistical significance, while trials that were terminated early had significant results. Positive trials were submitted for publication significantly more rapidly after completion than were negative trials (median, 1.0 vs 1.6 years; P=.001) and were published more rapidly after submission (median, 0.8 vs 1.1 years; P=.04). Conclusion.— Among randomized efficacy trials, there is a time lag in the publication of negative findings that occurs mostly after the completion of the trial follow-up},
}


@article{lyman2013,
  author = {Lyman, R. Lee},
  title = {{A Three-Decade History of the Duration of Peer Review}},
  journal = {JOURNAL OF SCHOLARLY PUBLISHING},
  year = {{2013}},
  volume = {{44}},
  number = {{3}},
  pages = {{211-220}},
  month = {{APR}},
  abstract = {{Review time is the duration between submission of a manuscript for possible publication and the author's receipt of notification of the editor's decision. There are two key questions about the peer-review process: (1) Has average review time changed over the past several decades? and (2) Has the adoption of online submission reduced average review time? A sample of 170 manuscripts submitted to a variety of journals from 1980 through 2012 indicates (1) no statistically significant difference between average review time for manuscripts submitted to behavioural science journals (mean = 14.8 weeks) and average review time for manuscripts submitted to natural history journals (mean = 15.2 weeks); (2) a statistically significant decrease from 1980 to 2012 in average review time irrespective of form of submission (i.e., paper or electronic); and (3) manuscripts submitted in paper form (1980-2009) had an average review time five weeks longer than that of manuscripts submitted online or electronically (2004-2012).}},
  doi = {{10.3138/jsp.44.3.001}},
  issn = {{1198-9742}},
  unique-id = {{ISI:000317941800001}},
}
